| 單位 | 全名        | 大小（十進位制）          |
|------|------------|----------------------------|
| KB   | Kilobyte   | 1,000 Bytes                |
| MB   | Megabyte   | 1,000 KB = 1,000,000 Bytes |
| GB   | Gigabyte   | 1,000 MB = 10⁹ Bytes       |
| TB   | Terabyte   | 1,000 GB = 10¹² Bytes      |
| PB   | Petabyte   | 1,000 TB = 10¹⁵ Bytes      |
| EB   | Exabyte    | 1,000 PB = 10¹⁸ Bytes      |
| ZB   | Zettabyte  | 1,000 EB = 10²¹ Bytes      |
| YB   | Yottabyte  | 1,000 ZB = 10²⁴ Bytes      |

***

| 二進位單位  | 全名        | 大小（2 的次方）        |
|------------|------------|--------------------------|
| KiB        | Kibibyte   | 1,024 Bytes (2¹⁰)        |
| MiB        | Mebibyte   | 1,024 KiB = 2²⁰ Bytes    |
| GiB        | Gibibyte   | 1,024 MiB = 2³⁰ Bytes    |
| TiB        | Tebibyte   | 1,024 GiB = 2⁴⁰ Bytes    |
| PiB        | Pebibyte   | 1,024 TiB = 2⁵⁰ Bytes    |
| EiB        | Exbibyte   | 1,024 PiB = 2⁶⁰ Bytes    |
| ZiB        | Zebibyte   | 1,024 EiB = 2⁷⁰ Bytes    |
| YiB        | Yobibyte   | 1,024 ZiB = 2⁸⁰ Bytes    |

***

CPU (Central Processing Unit)
Function: General-purpose processor that executes operating systems, applications, and manages hardware resources.
Architecture: Usually has a small number of powerful cores (4–16 cores), good at sequential tasks and multitasking.
Use cases: Everyday computing, office software, web browsing, gaming, etc.
Examples: Intel Core i7, AMD Ryzen 7.

GPU (Graphics Processing Unit)
Function: Designed for parallel processing, excels at handling large amounts of similar operations simultaneously.
Architecture: Contains hundreds to thousands of cores optimized for parallel data processing.
Use cases: Gaming graphics rendering, scientific computing, deep learning training.
Examples: NVIDIA RTX 3080, AMD Radeon RX 6800.

TPU (Tensor Processing Unit)
Function: Google’s custom accelerator designed specifically for deep learning matrix operations.
Architecture: Contains large numbers of matrix multiplication units optimized for tensor operations.
Use cases: Large-scale machine learning training and inference, primarily used in Google Cloud.
Examples: TPU v4, TPU v7.

NPU (Neural Processing Unit)
Function: Specialized accelerator optimized for neural network inference tasks.
Architecture: Typically integrated into mobile devices, supports low-precision operations like INT8 or INT4 for efficiency.
Use cases: AI applications on mobile devices, such as voice recognition, image recognition.
Examples: Apple Neural Engine (ANE), Qualcomm Hexagon NPU.


